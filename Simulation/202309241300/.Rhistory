gamma1$requires_grad_()
gamma2$requires_grad_()
theta <- list(B11=B11, B12=B12, B21d=B21d, B22d=B22d, B31=B31, B32=B32,
Lmdd=Lmdd, Qd=Qd, Rd=Rd, gamma1=gamma1, gamma2=gamma2)
jEta <- torch_full(c(N,Nt+1,2,2,L1), 0)
jP <- torch_full(c(N,Nt+1,2,2,L1,L1), 0)
jV <- torch_full(c(N,Nt,2,2,O1), NaN)
jF <- torch_full(c(N,Nt,2,2,O1,O1), NaN)
jEta2 <- torch_full(c(N,Nt,2,2,L1), 0)
jP2 <- torch_full(c(N,Nt,2,2,L1,L1), 0)
mEta <- torch_full(c(N,Nt+1,2,L1), 0)
mP <- torch_full(c(N,Nt+1,2,L1,L1), NaN)
W <- torch_full(c(N,Nt,2,2), NaN)
jPr <- torch_full(c(N,Nt+1,2,2), 0)
mLik <- torch_full(c(N,Nt), NaN)
jPr2 <- torch_full(c(N,Nt,2,2), 0)
mPr <- torch_full(c(N,Nt+1,2), NaN)
jLik <- torch_full(c(N,Nt,2,2), 0)
tPr <- torch_full(c(N,Nt+1,2,2), NaN)
KG <- torch_full(c(N,Nt,2,2,L1,O1), 0)
I_KGLmd <- torch_full(c(N,Nt,2,2,L1,L1), NaN)
subEta <- torch_full(c(N,Nt,2,2,L1), NaN)
eta1_pred <- torch_full(c(N,Nt,L1), NaN)
mP[,1,,,] <- torch_eye(L1)
mPr[,1,1] <- 1
mPr[,1,2] <- 0
tPr[,,1,2] <- 0
tPr[,,2,2] <- 1
B21 <- B21d$diag()
B22 <- B22d$diag()
Lmd <- Lmdd$reshape(c(O1, L1))
LmdT <- Lmd$transpose(1, 2)
Q <- Qd$diag()
R <- Rd$diag()
B1 <- torch_cat(c(B11, B12))$reshape(c(2, L1))
B2 <- torch_cat(c(B21, B22))$reshape(c(2, L1, L1))
B3 <- torch_cat(c(B31, B32))$reshape(c(2, L1))
for (t in 1:Nt) {
#################
# Kalman filter #
#################
jEta[,t,,,] <- B1$expand(c(N, -1, -1))$unsqueeze(-2) + mEta[,t,,]$clone()$unsqueeze(2)$matmul(B2) + eta2$unsqueeze(-1)$unsqueeze(-1)$unsqueeze(-1) * B3$expand(c(N, -1, -1))$unsqueeze(-2)
jP[,t,,,,] <- mP[,t,,,]$unsqueeze(2)$matmul(B2[2,,]**2) + Q$expand(c(N, 2, 2, -1, -1))
jV[,t,,,] <- y1[,t,]$unsqueeze(-2)$unsqueeze(-2) - jEta[,t,,,]$clone()$matmul(LmdT)
jF[,t,,,,] <- Lmd$matmul(jP[,t,,,,]$matmul(LmdT)) + R
KG[,t,,,,] <- jP[,t,,,,]$matmul(LmdT)$matmul(jF[,t,,,,]$clone()$cholesky_inverse())
jEta2[,t,,,] <- jEta[,t,,,] + KG[,t,,,,]$clone()$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()
I_KGLmd[,t,,,,] <- torch_eye(L1)$expand(c(N,2,2,-1,-1)) - KG[,t,,,,]$clone()$matmul(Lmd)
jP2[,t,,,,] <- I_KGLmd[,t,,,,]$clone()$matmul(jP[,t,,,,]$clone())$matmul(I_KGLmd[,t,,,,]$clone()$transpose(4, 5)) +
KG[,t,,,,]$clone()$matmul(R)$matmul(KG[,t,,,,]$clone()$transpose(4, 5))
jLik[,t,,] <- sEpsilon + const * jF[,t,,,,]$clone()$det()$clip(min=sEpsilon, max=ceil)**(-1) *
(-.5 * jF[,t,,,,]$clone()$cholesky_inverse()$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()$unsqueeze(-2)$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()$squeeze())$exp()
###################
# Hamilton filter #
###################
eta1_pred[,t,] <- mPr[,t,1]$clone()$unsqueeze(-1) * mEta[,t,1,]$clone() + mPr[,t,2]$clone()$unsqueeze(-1) * mEta[,t,2,]$clone()
tPr[,t,1,1] <- (gamma1 + eta1_pred[,t,]$clone()$matmul(gamma2))$sigmoid()$clip(min=sEpsilon, max=1-sEpsilon)
tPr[,t,2,1] <- 1 - tPr[,t,1,1]
jPr[,t,,] <- tPr[,t,,]$clone() * mPr[,t,]$clone()$unsqueeze(-1)
mLik[,t] <- (jLik[,t,,]$clone() * jPr[,t,,]$clone())$sum(c(2,3))
jPr2[,t,,] <- jLik[,t,,]$clone() * jPr[,t,,]$clone() / mLik[,t]$clone()$unsqueeze(-1)$unsqueeze(-1)
mPr[,t+1,] <- jPr2[,t,,]$sum(3)$clip(min=sEpsilon, max=1-sEpsilon)
W[,t,,] <- jPr2[,t,,]$clone() / mPr[,t+1,]$clone()$unsqueeze(-1)
mEta[,t+1,,] <- (W[,t,,]$clone()$unsqueeze(-1) * jEta2[,t,,,]$clone())$sum(3)
subEta[,t,,,] <- mEta[,t+1,,]$unsqueeze(2) - jEta2[,t,,,]
mP[,t+1,,,] <- (W[,t,,]$clone()$unsqueeze(-1)$unsqueeze(-1) * (jP2[,t,,,,] + subEta[,t,,,]$clone()$unsqueeze(-1)$matmul(subEta[,t,,,]$clone()$unsqueeze(-2))))$sum(3) }
loss <- -mLik$sum()
if (!is.finite(as.numeric(loss))) {
print('   error in calculating the sum likelihood')
with_no_grad ({
for (var in 1:length(theta)) {theta[[var]]$requires_grad_(FALSE)} })
break }
if (init == 1 && iter == 1) {
sumLik_list <- sumLik_init <- sumLik_new <- data.frame(init=init, iter=iter, value=-as.numeric(loss))
theta_list <- data.frame(init=init, iter=iter, params=1:length(torch_cat(theta)), value=as.numeric(torch_cat(theta)))
} else {
sumLik_prev <- sumLik_new
sumLik_new <- data.frame(init=init, iter=iter, value=-as.numeric(loss))
theta_new <- data.frame(init=init, iter=iter, params=1:length(unlist(theta)), value=as.numeric(torch_cat(theta)))
if (iter == 1) {sumLik_init <- sumLik_new}
sumLik_list <- rbind(sumLik_list, sumLik_new)
theta_list <- rbind(theta_list, theta_new)
crit <- ifelse(abs(sumLik_new$value - sumLik_init$value) > sEpsilon, (sumLik_new$value - sumLik_prev$value) / (sumLik_new$value - sumLik_init$value), 0)
count <- ifelse(crit < stopCrit, count + 1, 0)
if (init > 1 && iter == 100) {if (sumLik_new$value < .8 * max(sumLik_list$value[sumLik_list$init==init-1], na.rm=TRUE)) {break} }
if (count >= 3 || iter == maxIter) {
print('   stopping criterion is met')
with_no_grad ({
for (var in 1:length(theta)) {theta[[var]]$requires_grad_(FALSE)} })
break
} else if (sumLikBest < sumLik_new$value) {
initBest <- init
iterBest <- iter
thetaBest <- as.numeric(torch_cat(theta)); names(thetaBest) <- names(theta)
sumLikBest <- sumLik_new$value } }
cat('   sumLik = ', sumLik_new$value, '\n')
loss$backward()
grad <- list()
with_no_grad ({
for (var in 1:length(theta)) {
grad[[var]] <- theta[[var]]$grad
if (max(!is.finite(as.numeric(torch_cat(grad[[var]]))))) {
count <- 3; theta[[var]]$requires_grad_(FALSE); break}
if (iter == 1) {m[[var]] <- v[[var]] <- torch_zeros_like(grad[[var]])}
# update moment estimates
m[[var]] <- betas[1] * m[[var]] + (1 - betas[1]) * grad[[var]]
v[[var]] <- betas[2] * v[[var]] + (1 - betas[2]) * grad[[var]]**2
# update bias corrected moment estimates
m_hat[[var]] <- m[[var]] / (1 - betas[1]**iter)
v_hat[[var]] <- v[[var]] / (1 - betas[2]**iter)
theta[[var]]$requires_grad_(FALSE)
theta[[var]]$sub_(lr * m_hat[[var]] / (sqrt(v_hat[[var]]) + epsilon)) } })
B11 <- torch_tensor(theta$B11)
B12 <- torch_tensor(theta$B12)
B21d <- torch_tensor(theta$B21d)
B22d <- torch_tensor(theta$B22d)
B31 <- torch_tensor(theta$B31)
B32 <- torch_tensor(theta$B32)
Lmdd <- torch_tensor(theta$Lmdd); Lmdd[c(1,8)] <- 1; Lmdd[c(2,4,6,7,9,11)] <- 0
Qd <- torch_tensor(theta$Qd); Qd$clip_(min=lEpsilon)
Rd <- torch_tensor(theta$Rd); Rd$clip_(min=lEpsilon)
gamma1 <- torch_tensor(theta$gamma1)
gamma2 <- torch_tensor(theta$gamma2)
theta <- list(B11=B11, B12=B12, B21d=B21d, B22d=B22d, B31=B31, B32=B32,
Lmdd=Lmdd, Qd=Qd, Rd=Rd, gamma1=gamma1, gamma2=gamma2)
iter <- iter + 1 }
}) }
sumLik_prev
sumLik_new
sumLik_new
theta_new
B21 <- B21d$diag()
B22 <- B22d$diag()
# with_detect_anomaly ({
try (silent=FALSE, {
while (count <=3 && iter <= maxIter) {
cat('   optim step ', iter, '\n')
B11$requires_grad_()
B12$requires_grad_()
B21d$requires_grad_()
B22d$requires_grad_()
B31$requires_grad_()
B32$requires_grad_()
Lmdd$requires_grad_()
Qd$requires_grad_()
Rd$requires_grad_()
gamma1$requires_grad_()
gamma2$requires_grad_()
theta <- list(B11=B11, B12=B12, B21d=B21d, B22d=B22d, B31=B31, B32=B32,
Lmdd=Lmdd, Qd=Qd, Rd=Rd, gamma1=gamma1, gamma2=gamma2)
jEta <- torch_full(c(N,Nt+1,2,2,L1), 0)
jP <- torch_full(c(N,Nt+1,2,2,L1,L1), 0)
jV <- torch_full(c(N,Nt,2,2,O1), NaN)
jF <- torch_full(c(N,Nt,2,2,O1,O1), NaN)
jEta2 <- torch_full(c(N,Nt,2,2,L1), 0)
jP2 <- torch_full(c(N,Nt,2,2,L1,L1), 0)
mEta <- torch_full(c(N,Nt+1,2,L1), 0)
mP <- torch_full(c(N,Nt+1,2,L1,L1), NaN)
W <- torch_full(c(N,Nt,2,2), NaN)
jPr <- torch_full(c(N,Nt+1,2,2), 0)
mLik <- torch_full(c(N,Nt), NaN)
jPr2 <- torch_full(c(N,Nt,2,2), 0)
mPr <- torch_full(c(N,Nt+1,2), NaN)
jLik <- torch_full(c(N,Nt,2,2), 0)
tPr <- torch_full(c(N,Nt+1,2,2), NaN)
KG <- torch_full(c(N,Nt,2,2,L1,O1), 0)
I_KGLmd <- torch_full(c(N,Nt,2,2,L1,L1), NaN)
subEta <- torch_full(c(N,Nt,2,2,L1), NaN)
eta1_pred <- torch_full(c(N,Nt,L1), NaN)
mP[,1,,,] <- torch_eye(L1)
mPr[,1,1] <- 1
mPr[,1,2] <- 0
tPr[,,1,2] <- 0
tPr[,,2,2] <- 1
B21 <- B21d$diag()
B22 <- B22d$diag()
Lmd <- Lmdd$reshape(c(O1, L1))
LmdT <- Lmd$transpose(1, 2)
Q <- Qd$diag()
R <- Rd$diag()
B1 <- torch_cat(c(B11, B12))$reshape(c(2, L1))
B2 <- torch_cat(c(B21, B22))$reshape(c(2, L1, L1))
B3 <- torch_cat(c(B31, B32))$reshape(c(2, L1))
for (t in 1:Nt) {
#################
# Kalman filter #
#################
jEta[,t,,,] <- B1$expand(c(N, -1, -1))$unsqueeze(-2) + mEta[,t,,]$clone()$unsqueeze(2)$matmul(B2) + eta2$unsqueeze(-1)$unsqueeze(-1)$unsqueeze(-1) * B3$expand(c(N, -1, -1))$unsqueeze(-2)
jP[,t,,,,] <- mP[,t,,,]$unsqueeze(2)$matmul(B2[2,,]**2) + Q$expand(c(N, 2, 2, -1, -1))
jV[,t,,,] <- y1[,t,]$unsqueeze(-2)$unsqueeze(-2) - jEta[,t,,,]$clone()$matmul(LmdT)
jF[,t,,,,] <- Lmd$matmul(jP[,t,,,,]$matmul(LmdT)) + R
KG[,t,,,,] <- jP[,t,,,,]$matmul(LmdT)$matmul(jF[,t,,,,]$clone()$cholesky_inverse())
jEta2[,t,,,] <- jEta[,t,,,] + KG[,t,,,,]$clone()$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()
I_KGLmd[,t,,,,] <- torch_eye(L1)$expand(c(N,2,2,-1,-1)) - KG[,t,,,,]$clone()$matmul(Lmd)
jP2[,t,,,,] <- I_KGLmd[,t,,,,]$clone()$matmul(jP[,t,,,,]$clone())$matmul(I_KGLmd[,t,,,,]$clone()$transpose(4, 5)) +
KG[,t,,,,]$clone()$matmul(R)$matmul(KG[,t,,,,]$clone()$transpose(4, 5))
jLik[,t,,] <- sEpsilon + const * jF[,t,,,,]$clone()$det()$clip(min=sEpsilon, max=ceil)**(-1) *
(-.5 * jF[,t,,,,]$clone()$cholesky_inverse()$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()$unsqueeze(-2)$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()$squeeze())$exp()
###################
# Hamilton filter #
###################
eta1_pred[,t,] <- mPr[,t,1]$clone()$unsqueeze(-1) * mEta[,t,1,]$clone() + mPr[,t,2]$clone()$unsqueeze(-1) * mEta[,t,2,]$clone()
tPr[,t,1,1] <- (gamma1 + eta1_pred[,t,]$clone()$matmul(gamma2))$sigmoid()$clip(min=sEpsilon, max=1-sEpsilon)
tPr[,t,2,1] <- 1 - tPr[,t,1,1]
jPr[,t,,] <- tPr[,t,,]$clone() * mPr[,t,]$clone()$unsqueeze(-1)
mLik[,t] <- (jLik[,t,,]$clone() * jPr[,t,,]$clone())$sum(c(2,3))
jPr2[,t,,] <- jLik[,t,,]$clone() * jPr[,t,,]$clone() / mLik[,t]$clone()$unsqueeze(-1)$unsqueeze(-1)
mPr[,t+1,] <- jPr2[,t,,]$sum(3)$clip(min=sEpsilon, max=1-sEpsilon)
W[,t,,] <- jPr2[,t,,]$clone() / mPr[,t+1,]$clone()$unsqueeze(-1)
mEta[,t+1,,] <- (W[,t,,]$clone()$unsqueeze(-1) * jEta2[,t,,,]$clone())$sum(3)
subEta[,t,,,] <- mEta[,t+1,,]$unsqueeze(2) - jEta2[,t,,,]
mP[,t+1,,,] <- (W[,t,,]$clone()$unsqueeze(-1)$unsqueeze(-1) * (jP2[,t,,,,] + subEta[,t,,,]$clone()$unsqueeze(-1)$matmul(subEta[,t,,,]$clone()$unsqueeze(-2))))$sum(3) }
loss <- -mLik$sum()
if (!is.finite(as.numeric(loss))) {
print('   error in calculating the sum likelihood')
with_no_grad ({
for (var in 1:length(theta)) {theta[[var]]$requires_grad_(FALSE)} })
break }
if (init == 1 && iter == 1) {
sumLik_list <- sumLik_init <- sumLik_new <- data.frame(init=init, iter=iter, value=-as.numeric(loss))
theta_list <- data.frame(init=init, iter=iter, params=1:length(torch_cat(theta)), value=as.numeric(torch_cat(theta)))
} else {
sumLik_prev <- sumLik_new
sumLik_new <- data.frame(init=init, iter=iter, value=-as.numeric(loss))
theta_new <- data.frame(init=init, iter=iter, params=1:length(torch_cat(theta)), value=as.numeric(torch_cat(theta)))
if (iter == 1) {sumLik_init <- sumLik_new}
sumLik_list <- rbind(sumLik_list, sumLik_new)
theta_list <- rbind(theta_list, theta_new)
crit <- ifelse(abs(sumLik_new$value - sumLik_init$value) > sEpsilon, (sumLik_new$value - sumLik_prev$value) / (sumLik_new$value - sumLik_init$value), 0)
count <- ifelse(crit < stopCrit, count + 1, 0)
if (init > 1 && iter == 100) {if (sumLik_new$value < .8 * max(sumLik_list$value[sumLik_list$init==init-1], na.rm=TRUE)) {break} }
if (count >= 3 || iter == maxIter) {
print('   stopping criterion is met')
with_no_grad ({
for (var in 1:length(theta)) {theta[[var]]$requires_grad_(FALSE)} })
break
} else if (sumLikBest < sumLik_new$value) {
initBest <- init
iterBest <- iter
thetaBest <- as.numeric(torch_cat(theta)); names(thetaBest) <- names(theta)
sumLikBest <- sumLik_new$value } }
cat('   sumLik = ', sumLik_new$value, '\n')
loss$backward()
grad <- list()
with_no_grad ({
for (var in 1:length(theta)) {
grad[[var]] <- theta[[var]]$grad
if (max(!is.finite(as.numeric(torch_cat(grad[[var]]))))) {
count <- 3; theta[[var]]$requires_grad_(FALSE); break}
if (iter == 1) {m[[var]] <- v[[var]] <- torch_zeros_like(grad[[var]])}
# update moment estimates
m[[var]] <- betas[1] * m[[var]] + (1 - betas[1]) * grad[[var]]
v[[var]] <- betas[2] * v[[var]] + (1 - betas[2]) * grad[[var]]**2
# update bias corrected moment estimates
m_hat[[var]] <- m[[var]] / (1 - betas[1]**iter)
v_hat[[var]] <- v[[var]] / (1 - betas[2]**iter)
theta[[var]]$requires_grad_(FALSE)
theta[[var]]$sub_(lr * m_hat[[var]] / (sqrt(v_hat[[var]]) + epsilon)) } })
B11 <- torch_tensor(theta$B11)
B12 <- torch_tensor(theta$B12)
B21d <- torch_tensor(theta$B21d)
B22d <- torch_tensor(theta$B22d)
B31 <- torch_tensor(theta$B31)
B32 <- torch_tensor(theta$B32)
Lmdd <- torch_tensor(theta$Lmdd); Lmdd[c(1,8)] <- 1; Lmdd[c(2,4,6,7,9,11)] <- 0
Qd <- torch_tensor(theta$Qd); Qd$clip_(min=lEpsilon)
Rd <- torch_tensor(theta$Rd); Rd$clip_(min=lEpsilon)
gamma1 <- torch_tensor(theta$gamma1)
gamma2 <- torch_tensor(theta$gamma2)
theta <- list(B11=B11, B12=B12, B21d=B21d, B22d=B22d, B31=B31, B32=B32,
Lmdd=Lmdd, Qd=Qd, Rd=Rd, gamma1=gamma1, gamma2=gamma2)
iter <- iter + 1 }
}) }
theta_new
sumLik_new
#####################
# Measurement model #
#####################
model_cfa <- '
# latent variables
lv =~ ov1 + ov2 + ov3 '
y2_df <- as.data.frame(y2)
colnames(y2_df) <- c('ov1', 'ov2', 'ov3')
fit_cfa <- cfa(model_cfa, data=y2_df)
eta2_score <- lavPredict(fit_cfa, method='Bartlett')
eta2 <- as.array(eta2_score[,1])
y1 <- torch_tensor(y1)
eta2 <- torch_tensor(eta2)
sumLikBest <- 0
for (init in 1:nInit) {
cat('Init step ', init, '\n')
iter <- 1
count <- 0
m <- v <- m_hat <- v_hat <- list()
# initialize parameters
B11 <- torch_tensor(abs(rnorm(L1, 0, .3)))
B12 <- torch_tensor(-abs(rnorm(L1, 0, .2)))
B21d <- torch_tensor(runif(L1, .6, 1))
B22d <- torch_tensor(runif(L1, .2, .6))
B31 <- torch_tensor(abs(rnorm(L1, 0, .15)))
B32 <- torch_tensor(-abs(rnorm(L1, 0, .1)))
Lmdd <- torch_tensor(runif(O1*L1, .5, 1.5))
Lmdd[c(1,8)] <- 1; Lmdd[c(2,4,6,7,9,11)] <- 0
gamma1 <- torch_tensor(4) # fixed
gamma2 <- torch_tensor(abs(rnorm(L1, 0, 1)))
Qd <- torch_tensor(rep(.3, L1)) # fixed
Rd <- torch_tensor(rep(.5, O1)) # fixed
# with_detect_anomaly ({
try (silent=FALSE, {
while (count <=3 && iter <= maxIter) {
cat('   optim step ', iter, '\n')
B11$requires_grad_()
B12$requires_grad_()
B21d$requires_grad_()
B22d$requires_grad_()
B31$requires_grad_()
B32$requires_grad_()
Lmdd$requires_grad_()
Qd$requires_grad_()
Rd$requires_grad_()
gamma1$requires_grad_()
gamma2$requires_grad_()
theta <- list(B11=B11, B12=B12, B21d=B21d, B22d=B22d, B31=B31, B32=B32,
Lmdd=Lmdd, Qd=Qd, Rd=Rd, gamma1=gamma1, gamma2=gamma2)
jEta <- torch_full(c(N,Nt+1,2,2,L1), 0)
jP <- torch_full(c(N,Nt+1,2,2,L1,L1), 0)
jV <- torch_full(c(N,Nt,2,2,O1), NaN)
jF <- torch_full(c(N,Nt,2,2,O1,O1), NaN)
jEta2 <- torch_full(c(N,Nt,2,2,L1), 0)
jP2 <- torch_full(c(N,Nt,2,2,L1,L1), 0)
mEta <- torch_full(c(N,Nt+1,2,L1), 0)
mP <- torch_full(c(N,Nt+1,2,L1,L1), NaN)
W <- torch_full(c(N,Nt,2,2), NaN)
jPr <- torch_full(c(N,Nt+1,2,2), 0)
mLik <- torch_full(c(N,Nt), NaN)
jPr2 <- torch_full(c(N,Nt,2,2), 0)
mPr <- torch_full(c(N,Nt+1,2), NaN)
jLik <- torch_full(c(N,Nt,2,2), 0)
tPr <- torch_full(c(N,Nt+1,2,2), NaN)
KG <- torch_full(c(N,Nt,2,2,L1,O1), 0)
I_KGLmd <- torch_full(c(N,Nt,2,2,L1,L1), NaN)
subEta <- torch_full(c(N,Nt,2,2,L1), NaN)
eta1_pred <- torch_full(c(N,Nt,L1), NaN)
mP[,1,,,] <- torch_eye(L1)
mPr[,1,1] <- 1
mPr[,1,2] <- 0
tPr[,,1,2] <- 0
tPr[,,2,2] <- 1
B21 <- B21d$diag()
B22 <- B22d$diag()
Lmd <- Lmdd$reshape(c(O1, L1))
LmdT <- Lmd$transpose(1, 2)
Q <- Qd$diag()
R <- Rd$diag()
B1 <- torch_cat(c(B11, B12))$reshape(c(2, L1))
B2 <- torch_cat(c(B21, B22))$reshape(c(2, L1, L1))
B3 <- torch_cat(c(B31, B32))$reshape(c(2, L1))
for (t in 1:Nt) {
#################
# Kalman filter #
#################
jEta[,t,,,] <- B1$expand(c(N, -1, -1))$unsqueeze(-2) + mEta[,t,,]$clone()$unsqueeze(2)$matmul(B2) + eta2$unsqueeze(-1)$unsqueeze(-1)$unsqueeze(-1) * B3$expand(c(N, -1, -1))$unsqueeze(-2)
jP[,t,,,,] <- mP[,t,,,]$unsqueeze(2)$matmul(B2[2,,]**2) + Q$expand(c(N, 2, 2, -1, -1))
jV[,t,,,] <- y1[,t,]$unsqueeze(-2)$unsqueeze(-2) - jEta[,t,,,]$clone()$matmul(LmdT)
jF[,t,,,,] <- Lmd$matmul(jP[,t,,,,]$matmul(LmdT)) + R
KG[,t,,,,] <- jP[,t,,,,]$matmul(LmdT)$matmul(jF[,t,,,,]$clone()$cholesky_inverse())
jEta2[,t,,,] <- jEta[,t,,,] + KG[,t,,,,]$clone()$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()
I_KGLmd[,t,,,,] <- torch_eye(L1)$expand(c(N,2,2,-1,-1)) - KG[,t,,,,]$clone()$matmul(Lmd)
jP2[,t,,,,] <- I_KGLmd[,t,,,,]$clone()$matmul(jP[,t,,,,]$clone())$matmul(I_KGLmd[,t,,,,]$clone()$transpose(4, 5)) +
KG[,t,,,,]$clone()$matmul(R)$matmul(KG[,t,,,,]$clone()$transpose(4, 5))
jLik[,t,,] <- sEpsilon + const * jF[,t,,,,]$clone()$det()$clip(min=sEpsilon, max=ceil)**(-1) *
(-.5 * jF[,t,,,,]$clone()$cholesky_inverse()$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()$unsqueeze(-2)$matmul(jV[,t,,,]$clone()$unsqueeze(-1))$squeeze()$squeeze())$exp()
###################
# Hamilton filter #
###################
eta1_pred[,t,] <- mPr[,t,1]$clone()$unsqueeze(-1) * mEta[,t,1,]$clone() + mPr[,t,2]$clone()$unsqueeze(-1) * mEta[,t,2,]$clone()
tPr[,t,1,1] <- (gamma1 + eta1_pred[,t,]$clone()$matmul(gamma2))$sigmoid()$clip(min=sEpsilon, max=1-sEpsilon)
tPr[,t,2,1] <- 1 - tPr[,t,1,1]
jPr[,t,,] <- tPr[,t,,]$clone() * mPr[,t,]$clone()$unsqueeze(-1)
mLik[,t] <- (jLik[,t,,]$clone() * jPr[,t,,]$clone())$sum(c(2,3))
jPr2[,t,,] <- jLik[,t,,]$clone() * jPr[,t,,]$clone() / mLik[,t]$clone()$unsqueeze(-1)$unsqueeze(-1)
mPr[,t+1,] <- jPr2[,t,,]$sum(3)$clip(min=sEpsilon, max=1-sEpsilon)
W[,t,,] <- jPr2[,t,,]$clone() / mPr[,t+1,]$clone()$unsqueeze(-1)
mEta[,t+1,,] <- (W[,t,,]$clone()$unsqueeze(-1) * jEta2[,t,,,]$clone())$sum(3)
subEta[,t,,,] <- mEta[,t+1,,]$unsqueeze(2) - jEta2[,t,,,]
mP[,t+1,,,] <- (W[,t,,]$clone()$unsqueeze(-1)$unsqueeze(-1) * (jP2[,t,,,,] + subEta[,t,,,]$clone()$unsqueeze(-1)$matmul(subEta[,t,,,]$clone()$unsqueeze(-2))))$sum(3) }
loss <- -mLik$sum()
if (!is.finite(as.numeric(loss))) {
print('   error in calculating the sum likelihood')
with_no_grad ({
for (var in 1:length(theta)) {theta[[var]]$requires_grad_(FALSE)} })
break }
if (init == 1 && iter == 1) {
sumLik_list <- sumLik_init <- sumLik_new <- data.frame(init=init, iter=iter, value=-as.numeric(loss))
theta_list <- data.frame(init=init, iter=iter, params=1:length(torch_cat(theta)), value=as.numeric(torch_cat(theta)))
} else {
sumLik_prev <- sumLik_new
sumLik_new <- data.frame(init=init, iter=iter, value=-as.numeric(loss))
theta_new <- data.frame(init=init, iter=iter, params=1:length(torch_cat(theta)), value=as.numeric(torch_cat(theta)))
if (iter == 1) {sumLik_init <- sumLik_new}
sumLik_list <- rbind(sumLik_list, sumLik_new)
theta_list <- rbind(theta_list, theta_new)
crit <- ifelse(abs(sumLik_new$value - sumLik_init$value) > sEpsilon, (sumLik_new$value - sumLik_prev$value) / (sumLik_new$value - sumLik_init$value), 0)
count <- ifelse(crit < stopCrit, count + 1, 0)
if (init > 1 && iter == 100) {if (sumLik_new$value < .8 * max(sumLik_list$value[sumLik_list$init==init-1], na.rm=TRUE)) {break} }
if (count >= 3 || iter == maxIter) {
print('   stopping criterion is met')
with_no_grad ({
for (var in 1:length(theta)) {theta[[var]]$requires_grad_(FALSE)} })
break
} else if (sumLikBest < sumLik_new$value) {
initBest <- init
iterBest <- iter
thetaBest <- as.numeric(torch_cat(theta)); names(thetaBest) <- names(theta)
sumLikBest <- sumLik_new$value } }
cat('   sumLik = ', sumLik_new$value, '\n')
loss$backward()
grad <- list()
with_no_grad ({
for (var in 1:length(theta)) {
grad[[var]] <- theta[[var]]$grad
if (max(!is.finite(as.numeric(torch_cat(grad[[var]]))))) {
count <- 3; theta[[var]]$requires_grad_(FALSE); break}
if (iter == 1) {m[[var]] <- v[[var]] <- torch_zeros_like(grad[[var]])}
# update moment estimates
m[[var]] <- betas[1] * m[[var]] + (1 - betas[1]) * grad[[var]]
v[[var]] <- betas[2] * v[[var]] + (1 - betas[2]) * grad[[var]]**2
# update bias corrected moment estimates
m_hat[[var]] <- m[[var]] / (1 - betas[1]**iter)
v_hat[[var]] <- v[[var]] / (1 - betas[2]**iter)
theta[[var]]$requires_grad_(FALSE)
theta[[var]]$sub_(lr * m_hat[[var]] / (sqrt(v_hat[[var]]) + epsilon)) } })
B11 <- torch_tensor(theta$B11)
B12 <- torch_tensor(theta$B12)
B21d <- torch_tensor(theta$B21d)
B22d <- torch_tensor(theta$B22d)
B31 <- torch_tensor(theta$B31)
B32 <- torch_tensor(theta$B32)
Lmdd <- torch_tensor(theta$Lmdd); Lmdd[c(1,8)] <- 1; Lmdd[c(2,4,6,7,9,11)] <- 0
Qd <- torch_tensor(theta$Qd); Qd$clip_(min=lEpsilon)
Rd <- torch_tensor(theta$Rd); Rd$clip_(min=lEpsilon)
gamma1 <- torch_tensor(theta$gamma1)
gamma2 <- torch_tensor(theta$gamma2)
theta <- list(B11=B11, B12=B12, B21d=B21d, B22d=B22d, B31=B31, B32=B32,
Lmdd=Lmdd, Qd=Qd, Rd=Rd, gamma1=gamma1, gamma2=gamma2)
iter <- iter + 1 }
}) }
filter <- list(thetaBest=thetaBest, sumLikBest=sumLikBest, initBest=initBest, iterBest=iterBest, theta_list=theta_list, sumLik_list=sumLik_list)
filter
filter$theta_list
filter$sumLik_list
thetaBest
filter$thetaBest
torch(eye(2))
(torch_eye(2))
(torch_eye(2))$sum(2)
(torch_eye(2))$sum(1)
(torch_eye(2))$sum(1, keepdim = TRUE)
(torch_eye(2))$sum(2, keepdim = TRUE)
(torch_eye(2))$sum(1, keepdim = TRUE)
loss
table(factor(S[,Nt+1], levels=c(1,2)), factor(1 + round(as.numeric(mPr[,Nt+2,2])), levels=c(1,2)))
print(c(ind, seed))
N <- N_vec[ind]
Nt <- Nt_vec[ind]
N
Nt
df <- DGP(seed, N, Nt, O1, O2, L1)
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
nInit
maxIter
source('filtering_202309241300.R')
source('filtering_202309241300.R')
setwd('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300')
source('filtering_202309241300.R')
stopCluster(cl)
df <- DGP(seed, N, Nt, O1, O2, L1)
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
source('filtering_202309241300.R')
source('filtering_202309241300.R')
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
source('filtering_202309241300.R')
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
source('filtering_202309241300.R')
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
source('filtering_202309241300.R')
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
source('filtering_202309241300.R')
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
seed<-1
nInit <- 30/30
maxIter <- 300/10
source('filtering_202309241300.R')
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
source('filtering_202309241300.R')
#df <- readRDS(paste('C:/Users/kento/OneDrive - UT Cloud/Tuebingen/Research/Methods Center/Regime_Switching/Simulation/202309241300/output/df__sim_', seed, '_N_', N, '_T_', Nt, '_O1_', O1, '_O2_', O2, '_L1_', L1,'.RDS', sep=''))
filter <- filtering(seed, N, Nt, O1, O2, L1, df$y1, df$y2, df$S, df$eta1, nInit, maxIter)
filter
filter$theta_list
filter$theta_list[init==1 && param==1,]
filter$theta_list[init==1 && params==1,]
filter$theta_list[filter$theta_list$init==1 && filter$theta_list$params==1,]
filter$theta_list[filter$theta_list$init==1,][filter$theta_list$params==1,]
filter$output_list
